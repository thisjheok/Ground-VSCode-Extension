# Tool for Thought IDE 설계서

## 0. 문서 정보

* 문서 버전: v0.1
* 작성 목적: “코드 생성기”가 아닌 **사고를 증폭시키는 개발 도구**를 만들기 위한 제품/기술 설계 기준 확립
* 대상 독자: PM/리드 개발자/디자인/플러그인 개발자/ML 엔지니어

---

## 1. 문제 정의

### 1.1 배경

최근 IDE 보조 AI는 생산성을 높이지만, 사용자가 문제 정의·분해·검증을 AI에 위임하는 흐름(생각의 외주화)을 강화할 수 있음. 결과적으로 개발자는 결과물 “검증자”로 수렴하고, 설계 능력·디버깅 능력·메타인지가 약화될 수 있음.

### 1.2 해결하고자 하는 핵심 문제

* 사용자가 **근거(코드/로그/요구사항/제약)**에 직접 관여하지 않고 답을 “받는” 작업 흐름
* 설계 대안/트레이드오프를 탐색하지 않은 채 즉시 구현으로 진입하는 습관
* “테스트/검증/반례”의 부재로 인한 취약한 변경과 회귀
* 팀 단위의 아이디어 다양성 감소(모두 비슷한 패턴으로 수렴)

---

## 2. 목표와 비목표

### 2.1 제품 목표(Goals)

1. **자료에 대한 직접 관여 보존**: 사용자가 핵심 근거를 직접 읽고 선택하도록 유도
2. **생산적 저항 제공**: 자동 답변 대신 반례/반론/리스크/트레이드오프를 제시
3. **메타인지 스캐폴딩**: 목표·전략·검증을 사용자 손으로 명시하게 만들기
4. “채팅”이 아니라 IDE 워크플로우 속에서 자연스럽게 사고가 촉발되는 UI 제공
5. 팀/개인 작업 모두에 적용 가능(개인 모드 → PR/리뷰 모드 확장)

### 2.2 비목표(Non-Goals)

* “최대한 빨리 전체 코드를 완성해주는” 자동 코딩 에이전트(완전 대체형)
* 사용자의 의사결정 없이 대규모 자동 리팩토링을 수행하는 도구
* 사내/외부 모든 저장소에 대한 완전 자동 이해(초기에는 제한된 스코프)

---

## 3. 사용자 및 사용 시나리오

### 3.1 주요 사용자(Personas)

* A) 주니어 개발자: 문제 분해와 검증 루틴이 약함 → 사고 루틴을 학습하고 싶음
* B) 미들/시니어 개발자: 설계/리뷰 시 다양한 관점을 빠르게 점검하고 싶음
* C) 테크리드: 팀의 PR 품질과 회귀율을 줄이고 “근거 있는 의사결정” 문화를 만들고 싶음

### 3.2 대표 시나리오(Top Use Cases)

1. 버그 수정: 재현 → 근거 수집 → 가설 → 반례 점검 → 수정 → 회귀 테스트
2. 기능 추가: 요구사항/제약 명시 → 설계 대안 비교 → 구현 경계 결정 → 테스트 설계
3. 리팩토링: 목표/리스크 명시 → 영향 범위 증거 확보 → 단계적 변경 계획 → 검증
4. PR 작성/리뷰: 변경 근거 자동 정리 + 도발(레드팀) 질문 대응 기록

---

## 4. 제품 컨셉 및 핵심 원칙

### 4.1 컨셉 한 줄

**AI가 코드를 대신 작성하는 IDE가 아니라, 개발자가 더 잘 생각하도록 만드는 IDE.**

### 4.2 핵심 설계 원칙(3대 원칙)

* 원칙 A: **Evidence-first(근거 우선)**

  * 생성/수정 제안은 항상 근거 패키지(Evidence Pack)와 함께 제공
* 원칙 B: **Productive friction(생산적 마찰)**

  * 즉답 대신 도발(Provocations)로 대안·리스크·반례를 먼저 제시
* 원칙 C: **Metacognition scaffolding(메타인지 스캐폴딩)**

  * 성공 조건/제약/검증 계획을 사용자가 직접 작성해야 다음 단계가 열림

---

## 5. 사용자 경험(UX) 설계

### 5.1 UI 구성(IDE 패널 3종 + 최소 버튼)

* (1) **Outline 패널**: 목표/제약/대안/선택근거/검증계획
* (2) **Evidence 패널**: 관련 파일/심볼/테스트/로그/이슈 링크 묶음
* (3) **Provocation 패널**: 레드팀 질문, 반례, 위험, 트레이드오프, 테스트 제안
* (4) **Generate/Apply**(선택): 맨 마지막 단계에만 활성화

> 핵심: 채팅창 중심 UX를 피하고, “작업 흐름” 속에 AI를 배치

### 5.2 작업 흐름(Workflow)

#### Flow A: 버그 수정

1. 사용자: “증상/재현 절차” 입력
2. 시스템: Evidence Pack 자동 구성(관련 로그/스택트레이스/심볼/최근 변경)
3. 사용자: Outline에 “가설” 1~2줄 작성
4. 시스템: Provocations 생성(반례/경합/경계조건/검증 질문)
5. 사용자: “수용/보류/기각 + 이유” 기록
6. 선택: Generate Patch(최소 diff)
7. 시스템: 검증 체크리스트 및 추천 테스트 생성
8. 사용자: 실행 결과를 Evidence에 첨부(테스트 로그 등)

#### Flow B: 기능 추가

1. 요구사항/성공 조건 명시(필수)
2. 제약(성능/보안/호환/시간) 명시(필수)
3. 설계 대안 2개 제시(시스템이 도와주되, 사용자가 선택 근거 작성)
4. Provocations로 트레이드오프 점검
5. 구현 경계 확정 후에만 생성/스캐폴딩 버튼 활성화

### 5.3 “생산적 마찰” 규칙(UX Gate)

* Outline의 필수 필드(성공 조건/제약/검증 계획)가 비어 있으면:

  * AI는 “코드 생성” 대신 “질문/대안/근거”만 제공
* Provocation에 대한 최소 응답(수용/기각 이유 1줄)이 있어야:

  * Apply Patch가 활성화

---

## 6. 기능 요구사항

### 6.1 핵심 기능(MVP)

1. **Evidence Pack 생성**

   * 현재 파일/선택 영역/에러 로그/테스트 실패/최근 diff 기반 관련 코드 묶기
2. **Outline 템플릿 + 게이트**

   * 성공 조건, 제약, 접근 전략, 검증 계획을 구조화 입력
3. **Provocation Engine**

   * 반례/리스크/트레이드오프/테스트 제안 카드 생성
4. **Patch 생성(선택)**

   * 큰 코드 생성이 아니라 “최소 diff” 중심
5. **PR/노트 내보내기**

   * Outline + Provocation 응답 + Evidence 링크를 PR 텍스트로 export

### 6.2 확장 기능(Post-MVP)

* Lenses(렌즈) 뷰: Risk/Change/Invariants/Complexity 관점별 하이라이트
* 팀 룰셋(렌즈/도발 템플릿) 공유
* 리팩토링 단계 계획(스텝별 검증 포함)
* “회귀 가능성” 기반 테스트 자동 추천(커버리지/임팩트)

---

## 7. 비기능 요구사항

* 성능: IDE 사용 중 지연 최소화(로컬 인덱싱/캐시 활용)
* 신뢰성: 근거 링크/출처가 없는 주장은 금지(“추측” 표기)
* 보안/프라이버시:

  * 기본값: 로컬 처리 최대화, 업로드 최소화
  * 원격 LLM 사용 시: 민감정보 마스킹/옵트인/레포 단위 정책
* 추적 가능성: “왜 이 제안이 나왔는지” 근거(Evidence)를 항상 남김

---

## 8. 시스템 아키텍처(개요)

### 8.1 구성 요소

1. **IDE Plugin (Client)**

   * UI 패널(Outline/Evidence/Provocation)
   * 컨텍스트 수집(선택 코드, 열려있는 파일, 진단, 테스트 결과)
2. **Context Builder**

   * repo 인덱스/심볼 검색/의존 그래프/최근 변경 분석
   * Evidence Pack 구성
3. **Reasoning Orchestrator**

   * 단계 기반 프롬프트 실행(근거 → 도발 → 생성)
   * 게이트 로직(필수 필드/응답 여부)
4. **LLM Layer**

   * Provocations 생성, 대안 제시, 테스트 생성, 최소 diff 제안
5. **Storage (Local/Optional Remote)**

   * 작업 세션, outline, 도발 응답, evidence 참조 저장

### 8.2 데이터 흐름(요약)

* IDE 이벤트(테스트 실패/파일 선택/PR 모드) → Context Builder → Evidence Pack
* Evidence + Outline 입력 → Provocation Engine → 사용자 응답 기록
* 마지막 단계에서 Patch Generation(옵션) → 사용자 적용/검증 → 로그 저장

---

## 9. 프롬프트/정책 설계(핵심)

### 9.1 단계형 프롬프트(대화형이 아닌 파이프라인)

* Step 1: Evidence Pack 요약(“근거만”)
* Step 2: 설계 대안 생성(최대 3개, 각 트레이드오프 포함)
* Step 3: Provocations 생성(반례/리스크/검증 질문/테스트)
* Step 4: Patch 생성(옵션, 최소 diff, 근거 링크 포함)

### 9.2 정책(Guardrails)

* 근거 없는 단정 금지: “확실치 않음/추정” 표시
* 위험 작업은 질문 우선(보안/데이터 삭제/마이그레이션)
* 대규모 변경은 단계 계획과 검증이 없으면 제안 금지

---

## 10. 평가 계획(Evaluation)

### 10.1 성공 지표(정량)

* PR 내보내기에서 **근거 링크 포함률**
* Provocation 카드에 대한 **응답 기록률**
* 회귀율 감소(동일 유형 버그 재발률)
* 테스트 추가율(변경 대비 테스트 증가)
* 리뷰 코멘트 감소/변경 왕복 횟수 감소(품질 개선 시)

### 10.2 사용자 연구(정성)

* “왜 이렇게 바꿨는지 설명 가능성” 향상 여부
* 대안 탐색 경험(사고 다양성) 증가 여부
* 주니어의 디버깅/설계 학습 효과(체크리스트 습관화)

---

## 11. MVP 범위 및 일정(예시)

### 11.1 MVP 스코프(필수)

* VS Code 플러그인
* Outline/Evidence/Provocation 패널
* Evidence Pack: 파일/심볼 검색 + 테스트 실패 로그 첨부
* Provocation: 반례/리스크/테스트 제안
* Export: PR 텍스트 생성

### 11.2 제외(초기)

* 자동 리팩토링 대규모 실행
* 멀티레포/모노레포 전체 정밀 분석
* 팀 단위 대시보드(지표 시각화)

---

## 12. 리스크 및 대응

1. **마찰이 과해서 사용자가 떠남**

   * 대응: 게이트 강도를 “모드”로 제공(학습/표준/빠름)
2. **도발이 과잉 경고로 피로감 유발**

   * 대응: 우선순위/심각도 레벨링, 사용자 맞춤(프로젝트 성격 반영)
3. **근거 수집이 부정확하면 신뢰 붕괴**

   * 대응: Evidence Pack에 “포함 이유”를 명시하고 사용자가 편집 가능하게
4. **보안/프라이버시 이슈**

   * 대응: 로컬 우선, 옵트인 업로드, 마스킹, 레포 정책

---

## 13. 오픈 이슈(결정 필요)

* LLM 실행 위치: 로컬/사내/외부 API 중 기본값
* Evidence Pack의 최대 토큰/크기 제한 정책
* 언어/프레임워크 우선순위(예: TS/JS, Python, C++, Kotlin 등)
* “빠른 모드”에서 게이트를 어디까지 완화할지

---

# 부록 A. 화면 스펙(간단)

* Outline 필드(필수)

  * 성공 조건(Definition of Done)
  * 제약(성능/보안/호환/마감)
  * 검증 계획(어떤 테스트/로그로 성공 판단)
* Provocation 카드 타입

  * Counterexample / Hidden Assumption / Trade-off / Security / Performance / Test Gap
* Evidence Pack 항목

  * 관련 파일/심볼/콜스택/테스트/최근 변경 diff 링크

---

# 부록 B. MVP 데모 시나리오(추천)

* “테스트 실패 1건”을 입력으로 → Evidence 자동 구성 → 가설 작성 → 도발 응답 → 최소 diff 생성 → 테스트 통과 로그 첨부 → PR 내보내기
